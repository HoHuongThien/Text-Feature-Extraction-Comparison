{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import những thư viện cần thiết\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data file\n",
    "\n",
    "training_data = load_files(r\"./data1\", encoding=\"utf-8\")\n",
    "X, Y = training_data.data, training_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file chứa các từ stop_words\n",
    "\n",
    "stop_ws = []\n",
    "with open(\"vnstopword.txt\", encoding=\"utf-8\") as f :\n",
    "    text = f.read()\n",
    "    for word in text.split('\\n') :  #Tách ra mỗi dòng là 1 từ stopword riêng lẻ\n",
    "        stop_ws.append(word)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiền xử lý cho tập dữ liệu training\n",
    "documents = []\n",
    "sum_word = 0\n",
    "for sen in range(0, len(X)):\n",
    "    \n",
    "    # remove stop word\n",
    "    document = []\n",
    "    for word in str(X[sen]).split() :\n",
    "        sum_word = sum_word + 1         # Đếm tổng số từ trong tập dữ liệu\n",
    "        if (word not in stop_ws) :\n",
    "            if (\"_\" in word) or (word.isalpha() == True):\n",
    "                document.append(word)\n",
    "    #print(document)\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    replace_list = {\n",
    "        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n",
    "        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n",
    "        'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
    "        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
    "        'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
    "        ' okey ': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n",
    "        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ',\n",
    "        ' kg ': u' không ','not': u' không ', u' kg ': u' không ', ' k ': u' không ',' kh ':u' không ',' kô ':u' không ',' hok ':u' không ',' kp ': u' không phải ',u' kô ': u' không ', ' ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',' hong ':u' không',\n",
    "        'vs': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
    "        'đc': u' được ',' thick ': u' thích ', 'store': u' cửa hàng ',\n",
    "        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n",
    "        ' sấu ': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n",
    "        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
    "        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n",
    "        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n",
    "        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n",
    "        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n",
    "        ' dep ': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ','iu': u' yêu ','pv':u' phục vụ','nv':u' nhân viên','nc':u' nước',\n",
    "        u' hó ':u' khó',u' hắc ':u' khắc ','_': ' ', u' ng ':u' người '}\n",
    "\n",
    "    for k, v in replace_list.items():\n",
    "        document = document.replace(k, v)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Loại bỏ Hashtag\n",
    "    document = re.sub(r'#([^\\s]+)', '', document)\n",
    "    # Loại bỏ các URL\n",
    "    document = re.sub(r'http([^\\s]+)', '', document)\n",
    "    # Loại bỏ number có trong comment\n",
    "    document = re.sub(r'\\d+', '', document)\n",
    "    #Remove duplicated characters: vd: đẹppppppp\n",
    "    document = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), document, flags=re.IGNORECASE)\n",
    "    # Loại bỏ các dấu câu, các ký tự đặc biệt (Emoji, icon cũng bị remove)\n",
    "    document = re.sub(r'[^\\w\\s]','', document)\n",
    "    # Chuyển chữ in hoa thành chữ thường\n",
    "    document = document.lower()\n",
    "    # Loại bỏ các ký tự dư thừa đơn lẻ (Nhiều ký tự đơn lẻ liền nhau kg xử lý được)\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    # Loại bỏ các Emoji, icon\n",
    "    document = re.sub(r'[^\\w\\s,]', '', document)\n",
    "    # Loại bỏ nhiều khoảng trắng dư thừa\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Tokenization\n",
    "    document = ViTokenizer.tokenize(document)\n",
    "    \n",
    "    document = ''.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2962235\n"
     ]
    }
   ],
   "source": [
    "# Số lượng word trong tập dữ liệu\n",
    "print(sum_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân chia dữ liệu thành 2 phần: Training và Testing\n",
    "# X là data, Y là label\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stop_ws)\n",
    "X = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  0.33776378631591797  giây\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình huấn luyện bằng NaiveBayes\n",
    "\n",
    "import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Thêm biến này vào để kiểm tra thời gian huấn luyện\n",
    "start_NB = time.time()\n",
    "\n",
    "\n",
    "classifier_NB = BernoulliNB(binarize=None)\n",
    "classifier_NB.fit(X_Train, Y_Train)\n",
    "\n",
    "end_NB = time.time()\n",
    "time_NB = end_NB-start_NB\n",
    "\n",
    "#Show ra thời gian huấn luyện của mô hình\n",
    "#print(\"Thời gian huấn luyện: %s second\" % str(end-start))\n",
    "print(\"Thời gian huấn luyện: \", str(time_NB), \" giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  502.6755259037018  giây\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình huấn luyện bằng Random Forest\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Thêm biến này vào để kiểm tra thời gian huấn luyện\n",
    "start_RF = time.time()\n",
    "\n",
    "classifier_RF = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier_RF.fit(X_Train, Y_Train) \n",
    "\n",
    "end_RF = time.time()\n",
    "time_RF = end_RF-start_RF\n",
    "\n",
    "#Show ra thời gian huấn luyện của mô hình\n",
    "#print(\"Thời gian huấn luyện: %s second\" % str(end-start))\n",
    "print(\"Thời gian huấn luyện: \", str(time_RF), \" giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện:  516.385575056076  giây\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình huấn luyện bằng SVM\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Thêm biến này vào để kiểm tra thời gian huấn luyện\n",
    "start_SVM = time.time()\n",
    "\n",
    "classifier_SVM = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier_SVM.fit(X_Train, Y_Train)\n",
    "\n",
    "\n",
    "end_SVM = time.time()\n",
    "time_SVM = end_SVM-start_SVM\n",
    "\n",
    "#Show ra thời gian huấn luyện của mô hình\n",
    "#print(\"Thời gian huấn luyện: %s second\" % str(end-start))\n",
    "print(\"Thời gian huấn luyện: \", str(time_SVM), \" giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện Logistic Regression:  20.218449592590332  giây\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình huấn luyện bằng Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "\n",
    "classifier_LR = LogisticRegression(fit_intercept=True, n_jobs=4)\n",
    "classifier_LR.fit(X_Train, Y_Train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Thời gian huấn luyện Logistic Regression: \", str(end-start), \" giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian huấn luyện KNN:  5.6025390625  giây\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng mô hình huấn luyện bằng KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "classifier_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier_KNN.fit(X_Train, Y_Train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Thời gian huấn luyện KNN: \", str(end-start), \" giây\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Sentiment\n",
    "\n",
    "y_pred_NB = classifier_NB.predict(X_Test)\n",
    "\n",
    "y_pred_RF = classifier_RF.predict(X_Test)\n",
    "\n",
    "y_pred_SVM = classifier_SVM.predict(X_Test)\n",
    "\n",
    "#y_Pred_LR = classifier_LR.predict(X_Test)\n",
    "\n",
    "#y_Pred_KNN = classifier_KNN.predict(X_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes: 0.8336666666666667\n",
      "Accuracy of Random Forest: 0.8488888888888889\n",
      "Accuracy of SVM: 0.868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#print('Accuracy LogisticRegression: ', accuracy_score(Y_Test, y_Pred_LR))\n",
    "print('Accuracy of Naive Bayes:',accuracy_score(Y_Test, y_pred_NB))\n",
    "print('Accuracy of Random Forest:',accuracy_score(Y_Test, y_pred_RF))\n",
    "print('Accuracy of SVM:',accuracy_score(Y_Test, y_pred_SVM))\n",
    "#print('Accuracy KNN: ', accuracy_score(Y_Test, y_Pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Training time of NB:',time_NB)\n",
    "#print('Training time of RF:',time_RF)\n",
    "#print('Training time of SVM:',time_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
